* The Loveless Manifesto
  :PROPERTIES:
  :CUSTOM_ID: the-loveless-manifesto
  :END:

** Header and icons

@@html:<img src="./header.png" width="100%"/>@@    
   
Loveless icon, top layer first (or does this look like a dead compute?): 
- Stop:
  https://www.cleanpng.com/png-sign-stop-png-28453/ 
- Heart:
  https://twitter.com/cssanimation/status/672818174576955392 
- Compute:
  - Square. Pin spikes are the thing. 
  - In ascii: [</3] 
  - Or B&W using current style in AWS console 
    - https://www.shutterstock.com/image-illustration/set-vector-tech-computer-chip-icon-1433980736
  - Orange is EC2
  - How about both? color and B&W variant

** Inbox
   SCHEDULED: <2021-01-25 Mon>
https://netflix.github.io/conductor/
   
https://cloud.google.com/anthos
- https://cloudwars.co/google-cloud/google-cloud-seeing-extraordinary-demand-for-multicloud-anthos/

Loveless components are multi-contextable. By crafting components this
way a hybrid deploy (clouders and on-prem) can be pulled off. Of course
that would still involve a portable orchestrator

This document is entitled "The Loveless Manifesto" in reference to the
"[[https://www.youtube.com/watch?v=s1AiBi5gf1s][manifesto]]" documents that circulate within the Swift programming
community (as well as acknowledging that this document is a bit
long). A Swift manifesto serves to introduce a proposal which is
larger in scope than a single, small, specific idea. This document
follows that lighthearted nomenclature, in order to highlight that
there is a [[https://www.ribbonfarm.com/2012/08/16/realtechnik-nausea-and-technological-longing/][realtechnik]] "philosophy" driving the decisions behind what
is proposed herein.

Since on-prem serverless is developing, Loveless will be portable off
commercial cloud as well.

[[https://openwhisk.apache.org/][OpenWhisk]], under the Apache banner,
has been around for a while. The core compoents are called
[[https://github.com/apache/openwhisk/blob/master/docs/actions.md][Actions]].
Actions are the equivalent of Lambdas:

"Actions are stateless functions that run on the OpenWhisk platform...
An action may be created from a function programmed using a number of
supported languages and runtimes, or from a binary-compatible
executable, or even executables packaged as Docker containers.

Since Actions are dictionary in and dictionary out, Step Functions
should pass a dictionary to components?

[[https://github.com/kubeless/kubeless][Kubeless]]

bkubeless is a Kubernetes-native serverless framework that lets you
deploy small bits of code without having to worry about the underlying
infrastructure plumbing. It leverages Kubernetes resources to provide
auto-scaling, API routing, monitoring, troubleshooting and more.

Kubeless stands out as we use a Custom Resource Definition to be able to
create functions as custom kubernetes resources. We then run an
in-cluster controller that watches these custom resources and launches
runtimes on-demand. The controller dynamically injects the functions
code into the runtimes and make them available over HTTP or via a PubSub
mechanism.
   

** Abstract
   :PROPERTIES:
   :CUSTOM_ID: abstract
   :END:

As announced during re:Invent 2020, AWS has been playing match maker.
Docker and AWS Lambda have been hitched together, erasing the hard
boundary separating serverless from other compute models.

Cloud native AWS applications can now be viewed through a lens whereby
they consist of stateless components packaged as Docker container images
-- images that can run on AWS Lambda as well as other compute services.
Since the components in such an architecture are conceptually stateless,
a non-trivial app will need to be ochestrated via a potentially
long-running stateful mechanism. On AWS, the best way to accomplish that
is Step Functions.

Playing off the term "serverless," the label "Loveless" is herein coined
to refer to this new unified cloud architecture lens. The core model of
a Loveless architected app is Step Functions state machines
orchestrating stateless Docker containers, regardless of the specific
compute service they run on.

Now that AWS Lambda can be viewed as essentially just stateless Docker
billed by the millisecond, serverless is dead; long live serverless.

** Introduction
   :PROPERTIES:
   :CUSTOM_ID: introduction
   :END:

As is usual for an AWS re:Invent conference, the 2020 edition involved
[[https://aws.amazon.com/blogs/aws/aws-reinvent-announcements-2020/][many
announcements on multiple fronts]]. This document presents the results
of sifting through those for the implications affecting cloud
architects. In particular, there have been certain developments which
eable an architect to view AWS cloud-native apps through the existing
lens but with a new focus.

The particular re:Invent announcements that inspired this writing
include: -
[[https://aws.amazon.com/blogs/aws/new-for-aws-lambda-container-image-support/][New
for AWS Lambda -- Container Image Support]] -
[[https://aws.amazon.com/blogs/containers/introducing-aws-step-functions-integration-with-amazon-eks/][Introducing
AWS Step Functions integration with Amazon EKS]] -
[[https://aws.amazon.com/blogs/aws/new-for-aws-lambda-1ms-billing-granularity-adds-cost-savings/][New
for AWS Lambda -- 1ms Billing Granularity Adds Cost Savings]].
[[https://aws.amazon.com/about-aws/whats-new/2020/12/introducing-amazon-eks-distro/][Introducing
Amazon EKS Distro - an open source Kubernetes distribution used by
Amazon EKS.]] -
[[https://aws.amazon.com/blogs/containers/introducing-amazon-ecs-anywhere/][Introducing
Amazon ECS Anywhere]]

AWS is aligning Lambda and Docker, such that Lambda can be looked at as
simply another flavor of Docker available at the AWS compute buffet.
Arguably, this is evolutionary not revolutionary but it is a significant
refocusing which simplifies the mental model. This is how cloud-native
apps on AWS will be built this decade.

In response to these announcements, "Server Loveless" (or simply
"Loveless") is the light-hearted label herein coined for a cloud-native,
AWS-based application design pattern which is a refinement of the
serverless-first mindset. The twisting of the label "serverless" into
"server Loveless" is an attempt to pay homage to the valuable
contributions of serverless while also deemphasizing that fuzzy
marketing term -- a term which, moving forward, simply refers to a core
subset of best practices for cloud-native app design.

The ideal structure of a server Loveless app is that of Step Functions
orchestrating components which are all stateless Docker container
images, running on AWS Lambda as well as other AWS compute services.

Partially, the value of what is being proposed herein is what is absent.
For serverless-first designs there is now a way forward whereby there no
longer needs to be a dual architecture of serverless and the rest -- the
latter consisting of machinery where the compute does not occur on AWS
Lambda. A single architectural design can now be the main focus.

** Agenda
   :PROPERTIES:
   :CUSTOM_ID: agenda
   :END:

The imagined audience for this document is software developers and
architects building new, cloud-native apps atop AWS.

The title "The Loveless Manifesto" is intented to imply this document in
the style of a "Swift evolution manifesto," that is, a presentation of a
potential technical development roadmap involving multiple stages where
each stage provides concrete, accumulating value.

The main structure of the presentation is linear in time. First relevant
historical developments are presented. Next the implications thereof are
synthesized to provide a clear view of where we are now with regards to
designing cloud-native apps on AWS. Such a "how we got here" review
provides situational awareness of some of the myriad developments made
public around re:Invent 2020. A cloud architect might stop reading at
that point and have valuable take aways to put into practice.

After reviewing the past and present, potential futures developments are
considered. The Loveless architectural style is proposed in response to
some development rolled out at re:Invent 2020. The mental model proposed
immediate calls for novel bit of machinery. Building such is the main
next action being argued for herein.

If only the proposed bit of novel machinery is built, value could be
realized by folks building apps on AWS. Yet further out in time the main
proposal might be even be portable to other cloud providers. So, the
manifesto wraps up with a sketch of less immediate potential future
work.

** Terminology
   :PROPERTIES:
   :CUSTOM_ID: terminology
   :END:

*** Loveless
    :PROPERTIES:
    :CUSTOM_ID: loveless
    :END:

Titles evolve and usually include cooking things down to aa single word
variant that becomes the shorthand used by those involved. Earlier,
longer versions of a title for the ideas presented in this manifesto
include "server loveless architecture" and "server loveless." After
saying and writing that too many times, "Loveless" is the one word
banner that was settled upon.

The anscestral etymological root of Loveless is "serverless" and we all
know how easily that went down. Too clever by half twits just could not
resist demonstrating their brilliance, "How can it be serverless? There
are still servers involved."

An alternative naming possibility for Loveless could have been
"stateless-first," playing off of "serverless-first." Since a central
player core to Loveless apps is Step Functions, and Lambda (the original
serverless thing on AWS) is being de-emphasized, this alternative label
would have completed the analogy:

Lambda : Step Functions :: serverless-first : stateless-first

Implicit in all those labels is a lack of attachement to specific
servers, a tenant of robust cluster based computing which includes cloud
architectures. Ergo, Loveless.

** The Loveless model
   :PROPERTIES:
   :CUSTOM_ID: the-loveless-model
   :END:

The concrete goal is to have a clear mental model of how to design
cloud-native applications on AWS now and moving forward. A more loosely
defined, ancillary goal is a mental model which can also be put to use
on other cloud platforms. These priorities reflect the authors
experience: most work is done on AWS but Google Cloud and other cloud
providers are coming into play. A cloud vendor agnostic design toolbox
allows for shopping around based on price. E.g., Wasabi.

An analogy can be made to JavaSript in web browsers. JavaScript is
Turing complete so anything could be done with it but a sane subset of
functionality designed for a particular type of task in a specific
context leads to frameworks such as React, Angular, and Vue. Loveless is
like that but instead of web-native browser apps, the context is
cloud-native AWS apps.

*** Intro
    :PROPERTIES:
    :CUSTOM_ID: intro
    :END:

A cute label, such as server Loveless, in useful for Diffusion of
Innovation purposes; it gets a concept's foot in the door of reciever's
mind. More important is the value proposition associated with the label.
There had better be some follow up with some substance.

Loveless is an idiomatic way of writing scalable apps on AWS... yet also
reflect recent innovations which are reducing the significance of AWS
Lambda.

A three layer architecture for cloud deployed microservice applications.
The three layers consist of a container compute substrate, stateless
components floating within the substrate, and a central conductor
leading the orchestra of components.

At the bottom is the compute substrate, ones little cloud condensed out
of the computational ether. It is simply something that runs Dockerfile
specified containers. The serverless-or-not duality is no more.

Guided by Occam's razor the model is intentially as simple as possible.
Since the model is for AWS cloud-native application it also follows the
principle of "when in Rome, do as the Romans." While in AWS, only after
following the guidance of their tech talks and documentation is it time
to get creative.

--------------

Server Loveless is a design pattern for AWS hosted, cloud native
applications which mainly combines three main concepts: -
serverless-first as the design style - Step Functions as the stateful
orchestration mechanism - Docker for running stateless worker compoents
for Step Functions

Server Loveless is simply a refinement of serverless-first that adds a
mental models which unifies both serverless and that which cannot be
implemented given the current limitations of Lambda and friends. The
goal is to have Step Functions orchestrating stateless components,
designed as Lambda functions have always be coded up and then to add
framework code, an Activity server, which can run the same packaged
function code outside of AWS Lambda.

This refinement smooths the impedence mismatch between Lambda and the
other AWS compute services such that app components can simply be
designed as Lambdas (have the Lambda invocation interface, etc.) and the
appropriate compute service can be paired to the needs of the use case.
Example use cases that might require leaving AWS Lambda include if a GPU
is called for or if a Lambda function needs to run longer than the
fifteen minute AWS Lambda execution time limit.

Like serverless first, server Loveless reaches first for the serverless
toolbox and falls back to non-serverless tech only if necessary. The
refinement over serverless-first is that the same coding practices of
serverless are extended to the non-serverless components of the
architecture.

The label "server Loveless" does not mean leave AWS Serverless behind,
rather design the whole app a la serverless. That is the place to start;
and if it turns out something cannot run on AWS Lamba (say, it runs
longer than 15 minutes or a GPU would be really, really handy to have)
then simply deploy that Docker container image on ECS, Fargate, etc.

Lambda functions, the main compute components of serverless apps, are
naturally stateless. Server Loveless simply extends the statelessness
principle to all components, even those not running on AWS Lambda.
[[https://en.wikipedia.org/wiki/Service_statelessness_principle][Service
statelessness principle]] is one of the main design principles of SOAs,
so this is not a controversial nor novel idea.

OK, so on to the main point. What is meant by the term "Server Loveless
Architectures"? These are AWS cloud-native app architectures in which
the servers are Loveless, no sacred cows. Workers are stateless and
managed by Step Functions state machines.

The above defitions provide movitivation for the choice of adopting the
word "Loveless" into this architecture's name. (And, seemingly, geeks
cannot help themselves with punny wordplay.)

"Loveless" implies a design constraint that one cannot hug the servers.
The unloved servers are treated like the Vietnam War's
[[https://en.wikipedia.org/wiki/FNG_syndrome][FNG]]: considered
transient and prone to failure. "Loveless" as in it is wise not to form
emotional attachments.

"Loveless" as in no servers are put on a pedastal. The servers are
treated like cattle, not like sacred cows. Indeed some are even
sacrifial, killed off in [[https://aws.amazon.com/fis/][Chaos Monkey
style stress testing]].

Finally, "Loveless" is the one word label for the architecture. Saying
"Server Loveless" too many times gets annoying. Ironically, this may be
the logical conclusion of de-emphasizing "serverless." Shorter terms
such as "Loveless cloud architectures" or "Loveless apps" are less
cumbersome to work with that including the word "server." It also gets
confusing if one talks about a Server Loveless server.

A Lambda function is the simpliest implementation of a Step Function
Task.

AWS Lambda is now essentially just Docker billed by the millisecond.
Nonetheless, serverless started as AWS Lambda. The associated design
requirements of Lambda-based compute enforced multiple architectural
best practices that should continue to be followed, on Lambda and
beyond. This is what is meant by "serverless is dead; long live
serverless."

--------------

And AWS is driving customers towards using Step Functions to orchestrate
workflows using their cloud native compute services (Lambda, autoscaling
Docker, etc.).

The new Docker container support in Lambda is what enables the same
mental model to be applied to both serverless and other compute
services: they can all be seen as platforms to run Docker containers.

Loveless does whole heartedly run with one aspect of the Step Functions
mental model: the Step Functions is where state is maintained, Task
workers are stateless. Lambda is the quintessential stateless worker,
which is why it is the default Task implementation. Loveless aims for
Activities to also be stateless. It could be thought of it as
*stateless-first design.*

Points is Step Functions is another AWS service which strong encourages
modern, mature cloud app design. Server Loveless simply runs with the
design patterns of Lambda and Step Functions and implements the same on
Docker, irrespective of the underlying compute service... They can be
mentally modeled as HTTP API'd services.

Step Functions orchestrates a complex Docker app, interacting with the
containers through the Task and Activity interfaces. Any given Lambda
function-running Docker container might be on AWS Lambda or other
compute service (e.g., ECS). Step Functions handles retry logic, state
maintenance, etc. across the app components running within multiple
Docker containers. It kinda seems obvious when stated. But that's a nice
thing: it does make a lot of simple sence. It's clean, terse, and allows
a design to start simple (read: pure serverless at first).

Take the focus off of serverless and simply noodles a design pattern for
modern AWS cloud native apps.

Yet if one mentally runs through such a gedankenexperiment, the question
arises: could a Docker packaged Lambda function be run outside of Lamdda
as some kind of Activity? Mabye a bit of framework shim code which runs
Lambda functions in Docker containers host somewhere besides on Lambda.

So, if Lambda is now just lightweight Docker, and Lambda now bills in
1ms increments, serverless-first is simply a solid architecture for any
cloud-native app, with the flexibility to compute on Lambda, ECS, or
EKS, as per cost or workload.

Now, Lambda can be seen as simply another one of the Docker execution
platform offering available on AWS. But the design principles of
serverless expand to Docker in general, not just AWS Lambda anymore. The
Lambda microservice design principles, such as statelessness, are the
real value of serverless. Now we can focus on the component Function --
packaged as a Docker container image, interfaced with a la Step
Functions -- and run it on whichever compute platform is appropriate.

These developements enable a Docker centric refinement to the
serverless-first mentality. Things become clearer in that the various
AWS compute offerings are becoming more unified on a continuum. This is
not just a new Lambda features but a perspective that allows us to
simplify things. For example, why do we need Lambda layers anymore? They
simply become Docker image layers, or something:
[[https://aws.amazon.com/blogs/compute/working-with-lambda-layers-and-extensions-in-container-images/][AWS
Compute Blog: Working with Lambda layers and extensions in container
images]]. The focus moves to Docker, not Lambda. But we keep the
stateless microservice coding style.

Aligning AWS Lambda to Docker really simplifies serverless-first
designs: Dockerize, start on Lambda, migrate to EKS as needed for cost
or perf reasons.

[TODO: Image: - at top, step function logo - puppet stringing into
Docker zone - wherein there are both Lambda and ECS, EC2, and EKS
running/containing Docker logo - i.e. the whale container ship in all 4
- https://www.docker.com/company/newsroom/media-resources - Prior art: -
https://medium.com/better-programming/aws-lambda-now-supports-container-images-bff86b0f62b1
-
https://aws.amazon.com/blogs/compute/working-with-lambda-layers-and-extensions-in-container-images/
]

But it does lead one to a vantage where it is natural to wonder if

Another reason to build on Step Functions versus, say, some DIY
orchestration machinery is the mental momentum of already trained
developers and massive amounts of documentation. Step Functions is also
a common language tagging well defined concepts throughout a community
of developers.

*** Docker in Loveless
    :PROPERTIES:
    :CUSTOM_ID: docker-in-loveless
    :END:

Docker mostly just provides the compute cluster operating system. Step
Functions is the central nervous system orchestrating the app components
that run on Docker (which might incidentally be billed under the AWS
Lambda brand, or multiple other compute services).

In terms of division of labor, Docker handles the low-level physical
model of a compute cluster. Server Loveless delegates higher level,
logical structuring to Step Functions.

In terms of contribution to the server Loveless mindset, Docker brings
to the table the component packaging and delivery as well as the compute
platform's abstractions and infrastructure (control plane, auto-scaling,
etc.). Serverless brings the internal design of the packaged, stateless
components i.e. components built according to 12-factor app design. Step
Functions' contribution is orchestration which can bridge AWS Lambda and
other computer services, including those external to AWS such as
on-premise and and other cloud providers as needed.

The above billing news is about really short Lambda compute. Next we'll
get into too long Lambda compute i.e. what if a function, say, needs to
run for more than 15 mintes?

**** Enabled migrating to different compute servers for $$$
     :PROPERTIES:
     :CUSTOM_ID: enabled-migrating-to-different-compute-servers-for
     :END:

At a certain level of traffic, for purely financial reasons it may be
worth switching the compute from Lambda to EC2. For normal serverless
applications, those sorts of economics start to be financially worth
considering when scale gets in the range of ten million monthly hits.

Of course, one must keep an eye on the costs. Serverless can be quite
cost effective but when it comes to fully managed services (for
serverless or not), sometimes AWS wants way too much money in return for
simply removing a hassle.

Pricing comparisons between AWS Lambda and other AWS compute services is
not trivial. Lambda pricing depends on number of request, execution
duration, and amount of memory requested. Lambda pricing is pay as you
go, obviating wastage when capacity is over reserved as can happen on
other compute services.

an Nontheless, for EC2 reserving more capacity than required is
wasteful. Yet for many workloads a Lambda based implementation can end
up being significantly more economical.

Without working trough multiple examples of pricing comparision, suffice
to say, buying in bulk is always cheaper. One nice feature of Loveless
is that development can start purely running on Lambda and if things get
hot and heavy, compute can be easily migrated to another compute
service.

*** Boundaries, division of labor, compartmentalization of roles
    :PROPERTIES:
    :CUSTOM_ID: boundaries-division-of-labor-compartmentalization-of-roles
    :END:

Part of the value here is the mental model. Cross platform frameworks
always involve abstraction leaks. But this model can already guide
development on multiple cloud platforms.

The goal is for all state to reside in a Step Function state machine,
and the individual nodes in the graph, the States, to be stateless. In
the early days of Step Functions that obviously meant Lambda functions
which are by nature stateless. Now we can extend it to where Functions
run stateless on Lambda or other longer running compute services. This
is a natural process in serverless-first designs and AWS is making it
easier and easier.

Inspiration was taken from two of Gary Bernhardt presentations.
[[https://www.destroyallsoftware.com/screencasts/catalog/functional-core-imperative-shell][Functional
Core, Imperative Shell]] guided the idea that the core components should
be stateless (as functional as workers in Loveless can be).
[Boundaries](https://www.destroyallsoftware.com/talks/boundaries]
inspired the idea of passing simple values (read: ARNs) to the
components as a form of dependency injection.

Server Loveless is Boundaries applied to cloud apps i.e. the Dockerized
components are the functional internals and the Step Functions are the
imperative surface part. Core: FSM apps on cloud with nodes as stateless
servers.

*** Dependency injection
    :PROPERTIES:
    :CUSTOM_ID: dependency-injection
    :END:

In server Loveless designs, one technique for achieving statelessness is
via dependency injection. That is, rather than being hardcoded within a
component, things which do contain state -- such as a specific S3 bucket
-- are during invocation passed in by reference (read: ARNs). The
stateful behavior is encapsulated within the referenced services, not
the Docker hosted component. Only highly fault tolerant services are
used this was, such as S3, DynamoDB, SQS, and the other cloud usual
suspects. - The component is instructed by Step Function to perform a
Task - The Task's input Parameters fully describes the work to perform -
Identities of side-effecting services are dependency injects as ARNs

Stateless Docker components means they are easy to test. The interface
between Step Functions and a component is where dependency injection can
be applied "Do the following task, and use these resources (e.g. S3
buckets and DynamoDB databases) as your persistance" AWS IAM policies
and roles help in ensuring that some supposedly stateless component
really is not painting outside the lines prescribed.

Think of it as similar to TDD: - for the unit tess define the unit's
interface - write dummy unit internal code/functions that returns fails
- write tests that call into that intentionally failing dummy
implementation - finally start writing the real implementation atop that
dummy code

Apply that to Step Functions and the initial dummies are null Lambdas

Well, with server Loveless start with a Lambda function running on
Lambda. Get it running to some level of performance. Then if, say, some
code really could benefit from a GPU (which are not available on
Lambda), well, then migrate that stateless Function to some other Docker
platform which has GPUs available.

*** Loveless components
    :PROPERTIES:
    :CUSTOM_ID: loveless-components
    :END:

Ergo, design Docker components as stateless FSM nodes, which can run on
both Lambda and ECS via Step Functions Task interface. Core: FSM apps on
cloud with nodes as stateless servers. I.e. the architectural goal moves
from serverless-first to stateless-first. The Finite State Machine
represents the core "flowchart" of an app. [Bonus: the label
"serverless" gets demoted to a background character, & this moves
towards platform independent serverless apps.]

Where is serverless heading? Why use it? - It's not serverless anymore.
It's stateless first containers

Using the same interface is nice but there's also all the other
disciplines that come from Lambda design: stateless, single user, etc.

The component interface is the same as between Step Functions and
Lambda.

That's two good interfaces that sandwich an app component: • Above
between the task orchestrator (Step Functions) and a component • Below
between a component and its container platform (Docker)

Design Docker components as stateless FSM nodes, which can run on both
Lambda and ECS, both are interfaced with via Step Function APIs.

*** Loveless Activity Server
    :PROPERTIES:
    :CUSTOM_ID: loveless-activity-server
    :END:

DIY machinery to implement "event-driven serverless computing" on a
container platform. Working with Step Functions reduces the scope of
this first "MVP" component of a full vendor agnostic cloud-native
framework.

Although one could arguably say they are designing a Loveless
application without any new machinery coming into play, once the model
is comprehended, it becomes clear that with just a bit of new
technology, much more value could be realized. Therefore, a novel bit of
machinery is proposed, labeled a "Loveless Activity Server."

With a Loveless Activity Server, one could design cloud-native
applications for AWS which can flex to changing compute needs as a
project experiences real world usage demands or unanticipated
requirements. Such flexing can be necessitated for technical and/or
financial reasons.

how exactly is a Lambda function migrated off of AWS Lambda actually
made scalably and highly available as an Activity which can do work for
a Step Functions state machine.

https://aws.amazon.com/blogs/compute/working-with-lambda-layers-and-extensions-in-container-images/
> For Lambda, a container image includes the base operating system, >
the runtime, any Lambda extensions, your application code, and its >
dependencies. Lambda provides a set of open-source base images that >
you can use to build your container image... > You can build your own
custom runtime images starting with AWS > provided base images for
custom runtimes. You can add your preferred > runtime, dependencies, and
code to these images. To communicate with > Lambda, the image must
implement the Lambda Runtime API. We provide > Lambda runtime interface
clients for all supported runtimes, or you > can implement your own for
additional runtimes.

So a Loveless Activity server provides a Lambda equivalent runtime and a
mechanism for interfacing with Step Functions in the role of an
Activity.

In the past, serverless-first has meant starting with AWS Lambda plus
Step Functions and bringing in other AWS computer services as needed via
Activity Workers for use by Step Functions. Now a Lambda function can be
packaged as a Docker container image and that image can be deploy to AWS
Lambda. So, the next step (the architectural refinement) is to have an
autoscaling Docker set-up which maintains a pool of compute ready to
service a Step Function by running the Docker image containing the same
Lambda function but now, from the Step Functions perspective, it is seen
as an Activity not a Lambda Task. The Docker conatiner within which the
Lambda function runs is an activity worker. With this change of
perspective, a serverless-first app's development can start as a pure
serverless Step Functions app (i.e. involving no Activities) and as the
code complicates, add in other compute platforms using the same
serverless component design but deployed on activity workers rather than
AWS Lambda.

*** The economic perspective
    :PROPERTIES:
    :CUSTOM_ID: the-economic-perspective
    :END:

Since Lambda can now run Docker images, it can simply be seen as a
cloud-native Docker computer service.

AWS Lambda is simply becoming agile Docker, with tons of hooks into AWS
services. This is a big step towards platform agnostic serverless app
architecting. (Just need a FOSS platform independent Step Functions
implementation...)
[[https://aws.amazon.com/blogs/aws/new-for-aws-lambda-container-image-support/][New
for AWS Lambda -- Container Image Support]]

The serverless value proposition then reduces to a product packaging
issue: "For sale: we built these massive, internet scale services. In
order for you to be able to conveniently use them, we built plug-in
mechanisms where you can tack on in your (comparatively) little bit of
compute logic which we will run on AWS Lambda." That is still really
valuable but it is no longer core to an architect's design goals; it is
becoming simply how things are billed.

Why serverless, especially as Lambda and Docker become more similar?
Think of it in terms of 12-factor app design.
Serverless/serverless-first ensures that the architecture's components
have statelessness and disposability. Then Step Functions is where long
state is maintained, for example to handle a retry after a failure.

[A nice feature of this style is that the compute is just generic
cloud-able containerized tech i.e. Docker, Kubernetes, etc. The AWS
specific aspects are confined to Step Functions and the services. The
logic within the containers is the core and should be more amenable to
hybrid deployment.] This leads to positioning to functioning markets
based on pricing competition. Even if the code stays inside AWS, they
are very aggressive in terms of pricing for some generic services. So,
savings are still realizable within AWS.

** The longer future
   :PROPERTIES:
   :CUSTOM_ID: the-longer-future
   :END:

The idea of an open source Step Functions is not outrageous. In the
early days of Lambda base architectures, one had to roll their own
orchestration machinery. It is generic framework machinery.

Notice how GCP https://cloud.google.com/workflows Orchestrate Google
Cloud and HTTP-based API services into serverless workflows This aligns
with putting queue services behind email protocols.

If the architecture can reach cross vendor portability, that would add
another meaning to "Loveless" in that not only is an app not emotionally
attached to individual servers but it can also treat the cloud vendors
without love. And by love I mean the kind the Talking Heads referenced
in their song, No Compassion: "What are you, in love with your
problems?"

Part of modern cloud architecting best practices is the serverless
mindset. Here "serverless" refers to the looser definition of the word
rather that referring to AWS Lambda or a specific coding technique. That
is, for buy-dont-build tradeoff decisions, modulo pricing ourrages,
default to using services which require the least amount of management.
Jared Short did a good job of arguing this point in his talk at the 2020
Serverless Architecture Conference, [[https://youtu.be/XdPMvHzh2Lo][The
Serverless First Mindset]]

As evidenced by the re:Invent 2020 announcements around ECS and EKS, AWS
is addressing customer concerns about wanting a hybrid solution. But
hybrid design is the same set of technologies and ideas that multi-cloud
is built upon. The same principle Loveless uses on AWS will translate to
other cloud platforms. Even if a given project rightfully will never
migrate to another cloud provider, the architects tool box and the
architect can apply these ideas on multiple platforms.

The core of SFn is not that big a deal. Life of a serverless dev before
SFn involved DIY orchestrationg. The model on SFn could simply be
slavishliy copied (a new meaning to "lift and shift"). States Language
has a open definition. Even wihout such, Loveless mental model can be
used as a guide while coding on other platforms. Serverless
orchestration is somehing that every platform will provide. By
concentrating AWS lockin to just SFn, easier to port. gg

The above is for the near future. Yet looking further into the future...

Note the such Loveless application are tied to AWS because they depend
on Step Functions. Nonetheless the Loveless architecture structures code
in anticipation of being able to migrate between cloud providers But
that would require Step Functions to be platform portable,

But even if that does not come to be, life with a Loveless Activity
Server would be better.

As with any well crafted political missive, there should be value for as
many as possible. For those accepting an all AWS future: value. And for
those who want to get to more viscious pricing cometition, possiting
which encourages that to come about.

Finally, although this manifesto is not calling for it, the idea of an
open source implementation of Step Functions feels imminent. Given the
ECS and EKS developments of re:Invent, perhaps even AWS will provide
that. When something like this comes to be, the Loveless architecture
will be a Docker based cloud provider agnostic way of writing super
scalable applications.

Compared to an open source Step Functions, there is a lot less code
required to implement a Loveless Activity server. The Loveless Activity
server alone would complete a set of valuable technologies with
immediate utility. Mature apps could then be written following the
Loveless architecture. Of course, they would only run on AWS. At that
stage, Loveless is simply a clear, unified model for building
cloud-native AWS apps.

Later, an open source Step Function service would allow apps to be
multi-cloud portable, modulo any dependencies on AWS specific such at
DynamoDB.

Consider [[https://wasabi.com/s3-compatible-cloud-storage/][Wasabi]]: >
Wasabi is 80% cheaper and faster than Amazon S3 with free egress PLUS >
it's S3 Compatible... The S3-compatible API connectivity option for >
Wasabi Hot Cloud Storage provides a S3-compliant interface

Wasabi did such a good job of reimplementing S3 that AWS' boto3 Python
SDK can be used to interact with Wasabi. So, the same will likely happen
for things like the NoSQL database. That is, there will be a 100%
compatible replacement for DynamoDB. Vendor agnostic cloud apps are
coming. The vendors will be fungible for the disciplined architect,
enabling viscious pricing competition.

Docker by the millisecond

Mentally jacking Lambda up into the Docker world allows a dev to have a
portable multi-cloud architecture.

[[https://docs.microsoft.com/en-us/azure/logic-apps/logic-apps-overview][Azure
Logic Apps]]

[[https://cloud.google.com/blog/topics/developers-practitioners/better-service-orchestration-workflows][Google
Cloud Workflows]]
[[https://medium.com/google-cloud/a-first-look-at-serverless-orchestration-with-workflows-d80e41e9e04f][A
first look at serverless orchestration with Workflows]]
